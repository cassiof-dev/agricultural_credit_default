How many clients have defaulted: 6748 
Total of clients: 8000 

X_train shape: (24000, 13), y_train shape: (24000,)
X_test shape: (6000, 13), y_test shape: (6000,)
--- Random Forest Hyperparameter Tuning with RandomizedSearchCV ---
Fitting 5 folds for each of 20 candidates, totalling 100 fits

Best Parameters for Random Forest: {'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 0.5, 'max_depth': np.int64(3), 'class_weight': 'balanced'}
Best Precision Score (Cross-validated): 0.6372

--- Training and Evaluating Random Forest (Tuned) ---
Accuracy: 0.6133
Precision: 0.6468
Recall: 0.6059
F1-Score: 0.6257
ROC AUC Score: 0.6560

Classification Report:
              precision    recall  f1-score   support

 Not Default       0.58      0.62      0.60      2800
     Default       0.65      0.61      0.63      3200

    accuracy                           0.61      6000
   macro avg       0.61      0.61      0.61      6000
weighted avg       0.62      0.61      0.61      6000


Confusion Matrix:
[[1741 1059]
 [1261 1939]]

--- Training and Evaluating Logistic Regression ---
Accuracy: 0.6143
Precision: 0.6477
Recall: 0.6072
F1-Score: 0.6268
ROC AUC Score: 0.6531

Classification Report:
              precision    recall  f1-score   support

 Not Default       0.58      0.62      0.60      2800
     Default       0.65      0.61      0.63      3200

    accuracy                           0.61      6000
   macro avg       0.61      0.61      0.61      6000
weighted avg       0.62      0.61      0.61      6000


Confusion Matrix:
[[1743 1057]
 [1257 1943]]

--- Training and Evaluating K-Nearest Neighbors ---
Accuracy: 0.5658
Precision: 0.5863
Recall: 0.6316
F1-Score: 0.6081
ROC AUC Score: 0.5837

Classification Report:
              precision    recall  f1-score   support

 Not Default       0.54      0.49      0.51      2800
     Default       0.59      0.63      0.61      3200

    accuracy                           0.57      6000
   macro avg       0.56      0.56      0.56      6000
weighted avg       0.56      0.57      0.56      6000


Confusion Matrix:
[[1374 1426]
 [1179 2021]]

--- Comparative Analysis of Model Performance ---

Summary of Key Metrics:
                       accuracy  precision  recall  f1_score  roc_auc_score
model_name                                                                 
Random Forest (Tuned)    0.6133     0.6468  0.6059    0.6257         0.6560
Logistic Regression      0.6143     0.6477  0.6072    0.6268         0.6531
K-Nearest Neighbors      0.5658     0.5863  0.6316    0.6081         0.5837

--- Discussion and Implications ---
Based on **ROC AUC Score** (a good overall indicator for imbalanced datasets, measuring separability of classes), the **Random Forest (Tuned)** performed best.
For **F1-Score** (harmonic mean of precision and recall, balancing false positives and false negatives), the **Logistic Regression** showed the strongest balance.
When prioritizing **Precision** (minimizing false positives, e.g., incorrectly flagging a client as defaulting unnecessarily), the **Logistic Regression** was superior.
For **Recall** (minimizing false negatives, e.g., missing actual defaults, which can be costly), the **K-Nearest Neighbors** performed best.

**Implications for Data Adequacy (All Transactions):**
By analyzing all transactions instead of just the latest, the models are now learning patterns associated with individual loan behaviors and their outcomes. This can provide a more granular understanding of default drivers across the entire history of interactions.
The varying strengths across different models indicate that while the provided features are informative, the choice of model can significantly influence prediction performance for different business objectives. For instance, if the cost of missing a default (low recall) is higher than the cost of a false alarm (low precision), a model with higher recall might be preferred.
The generally positive performance across the models suggests that the selected features (`total_hectares_client`, `loan_amount`, etc.) are indeed **adequate and contain predictive power** for identifying default risk in individual transactions. However, there's always room for improvement through more advanced feature engineering (e.g., creating interaction terms, polynomial features, or explicitly incorporating time-series aspects if the sequence of transactions is important) or by exploring more complex models.
This comparative analysis helps confirm that the current dataset provides a solid foundation for building effective default prediction models on a transaction-by-transaction basis.
